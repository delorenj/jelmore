# NATS Event System Documentation\n\n## Overview\n\nThe Jelmore NATS event system provides comprehensive event-driven architecture for real-time communication and inter-service coordination. The system includes persistent event storage, dead letter queues, consumer groups for horizontal scaling, and monitoring capabilities.\n\n## Architecture\n\n### Core Components\n\n1. **Main Stream (JELMORE)**: Persistent event storage with 7-day retention\n2. **Dead Letter Queue (JELMORE_DLQ)**: Failed event storage with 30-day retention  \n3. **Consumer Groups**: Horizontal scaling for different event categories\n4. **Monitoring**: Real-time metrics and health monitoring\n\n### Stream Configuration\n\n```yaml\nJELMORE Stream:\n  Storage: Persistent file storage\n  Retention: 7 days (configurable)\n  Max Messages: 100,000\n  Max Bytes: 10GB\n  Discard Policy: Old messages when full\n  Duplicate Window: 60 seconds\n\nJELMORE_DLQ Stream:\n  Storage: Persistent file storage  \n  Retention: 30 days\n  Max Messages: 10,000\n  Max Bytes: 1GB\n```\n\n## Event Topics\n\nThe system supports the following event topics:\n\n### Session Events\n- `jelmore.session.created` - New session started\n- `jelmore.session.output` - Session output received\n- `jelmore.session.completed` - Session completed successfully\n- `jelmore.session.failed` - Session failed or errored\n- `jelmore.session.status` - Session status updates\n\n### File System Events\n- `jelmore.session.directory_changed` - Directory modifications\n- `jelmore.session.file_modified` - File changes\n\n### Git Events\n- `jelmore.session.git_activity` - Git operations (commit, push, etc.)\n\n## Consumer Groups\n\nConsumer groups enable horizontal scaling and specialized event processing:\n\n### 1. session_handlers\n- **Subjects**: `jelmore.session.>`\n- **Purpose**: General session event processing\n- **Scaling**: Multiple instances for load distribution\n\n### 2. file_watchers  \n- **Subjects**: `jelmore.session.directory_changed`, `jelmore.session.file_modified`\n- **Purpose**: File system monitoring and indexing\n- **Scaling**: Dedicated file processing workers\n\n### 3. git_monitors\n- **Subjects**: `jelmore.session.git_activity` \n- **Purpose**: Git activity tracking and repository management\n- **Scaling**: Git-specific processing\n\n### 4. system_monitors\n- **Subjects**: `jelmore.session.status`, `jelmore.session.failed`\n- **Purpose**: System health monitoring and alerting\n- **Scaling**: Health check and alert processing\n\n## Event Structure\n\nAll events follow a standardized structure:\n\n```json\n{\n  \"event_type\": \"session.created\",\n  \"session_id\": \"uuid-string\",\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\",\n  \"message_id\": \"unique-message-id\",\n  \"retry_count\": 0,\n  \"payload\": {\n    \"provider\": \"claude\",\n    \"timeout\": 7200,\n    \"additional_data\": \"...\"\n  }\n}\n```\n\n### Headers\n\nEvents include NATS headers for routing and deduplication:\n\n```\nNats-Msg-Id: unique-message-id  # Prevents duplicates\nEvent-Type: session.created      # Event classification\nSession-Id: uuid-string          # Session correlation\n```\n\n## Error Handling & Dead Letter Queue\n\n### Retry Logic\n- Maximum 3 delivery attempts per message\n- Exponential backoff: 2, 4, 8 seconds\n- Automatic DLQ routing after max attempts\n\n### Dead Letter Queue Events\nFailed events are enhanced with failure information:\n\n```json\n{\n  \"event_type\": \"session.created\",\n  \"session_id\": \"original-session-id\",\n  \"original_subject\": \"jelmore.session.created\",\n  \"dlq_timestamp\": \"2024-01-01T12:05:00.000Z\",\n  \"failure_reason\": \"Connection timeout\",\n  \"retry_count\": 3,\n  \"payload\": {\n    // Original event payload\n  }\n}\n```\n\n## API Usage\n\n### Publishing Events\n\n```python\nfrom jelmore.services.nats import publish_event\n\n# Basic event publishing\nsuccess = await publish_event(\n    event_type=\"session.created\",\n    session_id=\"session-uuid\", \n    payload={\"provider\": \"claude\", \"timeout\": 7200}\n)\n\n# With custom headers\nsuccess = await publish_event(\n    event_type=\"session.output\",\n    session_id=\"session-uuid\",\n    payload={\"content\": \"Hello world\", \"tokens\": 2},\n    headers={\"Priority\": \"high\"}\n)\n```\n\n### Subscribing to Events\n\n```python\nfrom jelmore.services.nats import subscribe_to_events\n\nasync def handle_session_events(event, msg):\n    print(f\"Received: {event['event_type']}\")\n    # Process event\n    await msg.ack()  # Acknowledge processing\n\n# Subscribe with consumer group\nsubscription = await subscribe_to_events(\n    subjects=[\"jelmore.session.>\"]\n    handler=handle_session_events,\n    consumer_group=\"session_handlers\",\n    auto_ack=False\n)\n```\n\n### Event Replay\n\n```python\nfrom jelmore.services.nats import replay_events\nfrom datetime import datetime, timedelta\n\n# Replay last hour of events\nstart_time = datetime.utcnow() - timedelta(hours=1)\nevents = await replay_events(\n    subjects=[\"jelmore.session.>\"],\n    start_time=start_time,\n    handler=process_replayed_event  # Optional\n)\n```\n\n## Monitoring & Metrics\n\n### Stream Health\n\n```python\nfrom jelmore.services.nats import get_stream_info\nfrom jelmore.services.nats_monitoring import get_health_status\n\n# Stream information\ninfo = await get_stream_info()\nprint(f\"Messages: {info['main_stream']['messages']}\")\nprint(f\"DLQ Messages: {info['dlq_stream']['messages']}\")\n\n# Health status\nhealth = await get_health_status()\nprint(f\"Status: {health['stream_health']}\")\nprint(f\"Consumer Lag: {health['consumer_lag']}\")\n```\n\n### Performance Metrics\n\n```python\nfrom jelmore.services.nats_monitoring import get_performance_metrics\n\nmetrics = await get_performance_metrics()\nprint(json.dumps(metrics, indent=2))\n```\n\n## Command Line Tools\n\n### Event Subscriber\n\n```bash\n# Subscribe to all events\npython scripts/nats_subscriber.py all\n\n# Subscribe with consumer group\npython scripts/nats_subscriber.py all --consumer-group session_handlers\n\n# Subscribe to specific subjects\npython scripts/nats_subscriber.py specific --subjects \"jelmore.session.created,jelmore.session.failed\"\n\n# Monitor dead letter queue\npython scripts/nats_subscriber.py dlq\n```\n\n### Test Utilities\n\n```bash\n# Publish test event\npython scripts/nats_test_utils.py publish --event-type session.created\n\n# Subscribe to events for 60 seconds\npython scripts/nats_test_utils.py subscribe --duration 60\n\n# Replay events from last 2 hours\npython scripts/nats_test_utils.py replay --hours 2\n\n# Check stream health\npython scripts/nats_test_utils.py health\n\n# Load testing (100 events/sec for 60 seconds)\npython scripts/nats_test_utils.py load --rate 100 --duration 60\n```\n\n## Integration with Jelmore\n\n### Session Lifecycle Events\n\n1. **Session Creation**: Published when new session starts\n2. **Status Updates**: Regular heartbeat and status changes\n3. **Output Events**: All session output (Claude responses, errors)\n4. **Completion**: Success or failure notifications\n5. **File Changes**: Real-time file system monitoring\n6. **Git Activity**: Repository change notifications\n\n### Event-Driven Features\n\n- **Real-time Dashboards**: Subscribe to session events for live updates\n- **Audit Logging**: Persistent event storage for compliance\n- **Monitoring Alerts**: Failed session notifications\n- **Analytics**: Event replay for usage analytics\n- **Integration**: External system notifications\n\n## Configuration\n\n### Environment Variables\n\n```env\nNATS_URL=nats://localhost:4222\nNATS_CLUSTER_ID=jelmore-cluster  \nNATS_CLIENT_ID=jelmore-api\nNATS_SUBJECT_PREFIX=jelmore\n```\n\n### Docker Compose\n\nThe system requires NATS server with JetStream enabled:\n\n```yaml\nservices:\n  nats:\n    image: nats:latest\n    command: [\n      \"--jetstream\",\n      \"--store_dir=/data\",\n      \"--max_memory_store=1GB\",\n      \"--max_file_store=10GB\"\n    ]\n    volumes:\n      - nats_data:/data\n    ports:\n      - \"4222:4222\"\n      - \"8222:8222\"  # HTTP monitoring\n```\n\n## Performance Characteristics\n\n### Throughput\n- **Publishing**: 10,000+ events/second per client\n- **Consuming**: Scales linearly with consumer instances\n- **Storage**: 10GB default capacity, configurable\n\n### Latency\n- **Publish Latency**: < 1ms typical\n- **End-to-end**: < 5ms for local delivery\n- **Persistent Storage**: < 10ms write latency\n\n### Scalability\n- **Horizontal**: Consumer groups scale independently\n- **Vertical**: Single stream handles millions of messages\n- **Geographic**: NATS clustering for multi-region\n\n## Best Practices\n\n### Event Design\n1. **Keep payloads small** (< 1KB preferred)\n2. **Use structured data** (JSON with schema)\n3. **Include correlation IDs** (session_id, message_id)\n4. **Add timestamps** for ordering and replay\n\n### Consumer Implementation\n1. **Use consumer groups** for scalability\n2. **Implement idempotent processing** (handle duplicates)\n3. **Monitor consumer lag** (alerts at > 100 pending)\n4. **Handle failures gracefully** (retry logic, error logging)\n\n### Monitoring\n1. **Track message rates** by event type\n2. **Monitor DLQ growth** (investigate > 10 messages)\n3. **Alert on consumer lag** (> 1000 pending)\n4. **Watch stream growth** (storage limits)\n\n## Troubleshooting\n\n### Common Issues\n\n#### High Consumer Lag\n```bash\n# Check consumer status\npython scripts/nats_test_utils.py health\n\n# Add more consumer instances\n# Scale consumer group horizontally\n```\n\n#### DLQ Growth\n```bash\n# Monitor DLQ\npython scripts/nats_subscriber.py dlq\n\n# Investigate failure patterns\n# Fix underlying issues\n# Replay DLQ events if needed\n```\n\n#### Connection Issues\n```bash\n# Check NATS server status\ncurl http://localhost:8222/varz\n\n# Verify network connectivity\ntelnet localhost 4222\n```\n\n### Debugging\n\nEnable debug logging:\n\n```python\nimport structlog\nstructlog.configure(level=\"DEBUG\")\n```\n\nUse NATS CLI tools:\n\n```bash\n# Install NATS CLI\ngo install github.com/nats-io/natscli/nats@latest\n\n# Stream info\nnats stream info JELMORE\n\n# Consumer info  \nnats consumer info JELMORE session_handlers\n```\n\n## Security\n\n### Authentication\n- **JWT Authentication**: Production deployments\n- **TLS Encryption**: Inter-service communication\n- **Subject-level ACLs**: Fine-grained permissions\n\n### Data Protection\n- **Message Encryption**: Sensitive payload encryption\n- **Audit Trails**: All access logged\n- **Retention Policies**: Automatic data expiry\n\n## Future Enhancements\n\n### Planned Features\n1. **Message Encryption**: End-to-end encryption for sensitive events\n2. **Schema Registry**: Event schema validation and evolution\n3. **Multi-Region**: NATS clustering for geographic distribution\n4. **Advanced Analytics**: Built-in event analytics and reporting\n5. **Webhook Integration**: HTTP callbacks for external systems\n6. **Event Sourcing**: Complete event-driven state reconstruction\n\n### Performance Optimizations\n1. **Message Compression**: Reduce bandwidth usage\n2. **Batch Processing**: Higher throughput consumer patterns\n3. **Connection Pooling**: Shared connections for efficiency\n4. **Caching Layer**: Hot event caching for frequent access\n\n---\n\n*For more information, see the [NATS Documentation](https://docs.nats.io/) and [JetStream Guide](https://docs.nats.io/jetstream)*